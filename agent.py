from llmclient import LLMClient
from tools import Tool
from typing import Dict, Any, List, Optional
import json,re
from prompt import create_prompt, create_planning_prompt
from log import logger, debug, info, warning, error, critical, exception
from database import db

import datetime

class ReactAgent:
    """å¢å¼ºå‹React Agentï¼ŒåŒ…å«LLMã€è®°å¿†ã€è§„åˆ’å’Œå·¥å…·ä½¿ç”¨åŠŸèƒ½"""
    
    def __init__(self, llm: LLMClient ,tools : Dict[str, Tool]):
        self.llm = llm
        self.tools = tools
        info(f"ReactAgentåˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½å·¥å…·æ•°é‡: {len(tools)}")

    def _create_analysis_prompt(self, user_input: str, user_id: int) -> str:
        """åˆ›å»ºåˆ†æç”¨æˆ·è¾“å…¥å†…å®¹ï¼Œå·¥å…·é€‰æ‹©å’Œå‚æ•°è¾“å…¥æç¤ºè¯"""
        tools_schema = []
        for tool in self.tools.values():
            tools_schema.append(tool.get_schema())
        # å†å²å¯¹è¯ï¼Œè¿™é‡Œçš„å†å²å¯¹è¯æ˜¯çŸ­æœŸè®°å¿†ï¼ŒåŒ…å«æœ€è¿‘çš„3æ¬¡å¯¹è¯ï¼Œå¿…é¡»æ·»åŠ ï¼Œå¦åˆ™LLMä¼šå¿˜è®°ä¹‹å‰çš„å¯¹è¯ï¼Œå› ä¸ºè¿™é‡Œæ˜¯åŸºäºæœ€è¿‘çš„å¯¹è¯å»ç”Ÿæˆæ‰§è¡Œçš„å·¥å…·ä¿¡æ¯ï¼Œ
        # å¦‚æœä¸æ·»åŠ ï¼ŒLLMä¼šåŸºäºå½“å‰å¯¹è¯å»ç”Ÿæˆæ‰§è¡Œçš„å·¥å…·ä¿¡æ¯ï¼Œè€Œä¸æ˜¯åŸºäºä¹‹å‰çš„å¯¹è¯å»ç”Ÿæˆæ‰§è¡Œçš„å·¥å…·ä¿¡æ¯ï¼Œè¿™æ ·ä¼šå¯¼è‡´å·¥å…·çš„å‚æ•°ä¼ é€’å‡ºé—®é¢˜
        # ä¾‹å¦‚å½“å‰é—®é¢˜çš„è¯·é—®ï¼Œæ˜¯åŸºäºä¸Šä¸€ä¸ªé—®é¢˜çš„ç»“æœï¼Œç°åœ¨éœ€è¦æŠŠä¸Šä¸€ä¸ªé—®é¢˜çš„ç»“æœæ·»åŠ ä¸ºå½“å‰é—®é¢˜ä¸­å·¥å…·è°ƒç”¨çš„æŸä¸€ä¸ªå‚æ•°å€¼
        # print("æŸ¥çœ‹ç¬¬äºŒä¸ªæç¤ºè¯çš„å·¥å…·schema: ",tools_schema)
        history=self._summarize_conversation(user_id)
        # print("æŸ¥çœ‹ç¬¬äºŒä¸ªæç¤ºè¯çš„å†å²è®°å½•: ",history)
        # æç¤ºè¯
        prompt=create_prompt(user_input,tools_schema,history)
        return prompt
        
    def _create_planning_prompt(self, user_input: str, conversation_summary: str) -> str:
        """åˆ›å»ºè§„åˆ’æç¤ºè¯"""
        tools_schema = []
        for tool in self.tools.values():
            tools_schema.append(tool.get_schema())
        # print("æŸ¥çœ‹ç¬¬ä¸€ä¸ªæç¤ºè¯çš„å·¥å…·schema: ",tools_schema)
        # ä¸‹é¢åˆ›å»ºçš„è§„åˆ’æç¤ºè¯ï¼ŒåŒ…å«ç”¨æˆ·è¾“å…¥ã€å·¥å…·schemaå’Œå¯¹è¯æ‘˜è¦ï¼ˆå†å²å¯¹è¯ï¼Œå¯ä»¥ä¸ç”¨æ·»åŠ ï¼Œæ ¹æ®éœ€è¦æ·»åŠ ï¼Œå¯¹è¯çš„æ¬¡æ•°æˆ‘é™åˆ¶ä¸º3æ¬¡ï¼‰
        prompt = create_planning_prompt(user_input, tools_schema, conversation_summary) 
        return prompt

        
    def parse_user_input(self, user_input: str, user_id: int) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè§£æç”¨æˆ·è¾“å…¥ï¼Œé€‰æ‹©å·¥å…·å¹¶æå–å‚æ•°"""
        try:
            debug(f"å¼€å§‹è§£æç”¨æˆ·è¾“å…¥: {user_input[:100]}..." if len(user_input) > 100 else f"å¼€å§‹è§£æç”¨æˆ·è¾“å…¥: {user_input}")
            prompt = self._create_analysis_prompt(user_input, user_id)
            # LLMé—®ç­”
            try:
                response = self.llm.chat(prompt) #è·å–éœ€è¦è°ƒç”¨çš„å·¥å…·å’Œå‚æ•°
                debug("LLMè§£æå“åº”è·å–æˆåŠŸ")
            except ConnectionError as ce:
                error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {ce}")
                return {"tool": None, "parameters": {}, "reasoning": "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦å¯ç”¨", "confidence": 0}
            except Exception as e:
                error(f"LLMè°ƒç”¨é”™è¯¯: {e}")
                return {"tool": None, "parameters": {}, "reasoning": f"LLMè°ƒç”¨å¼‚å¸¸: {str(e)}", "confidence": 0}

            # æå–JSON
            result = self._extract_json_from_response(response)

            # éªŒè¯jsonæ ¼å¼æ˜¯å¦ç¬¦åˆå·¥å…·è°ƒç”¨
            if result and self._validate_parsed_result(result):
                return result
            else:
                debug("è§£æç»“æœéªŒè¯å¤±è´¥")
                return {"tool": None, "parameters": {}, "reasoning": "è§£æå¤±è´¥", "confidence": 0}
                
        except Exception as e:
            error(f"è§£æé”™è¯¯: {e}")
            exception("ç”¨æˆ·è¾“å…¥è§£æå¼‚å¸¸")
            return {"tool": None, "parameters": {}, "reasoning": f"è§£æå¼‚å¸¸: {str(e)}", "confidence": 0}
    
    def create_plan(self, user_input: str, user_id: int) -> List[Dict]:
        """ä¸ºç”¨æˆ·è¾“å…¥åˆ›å»ºæ‰§è¡Œè®¡åˆ’"""
        try:
            info(f"å¼€å§‹åˆ›å»ºæ‰§è¡Œè®¡åˆ’ï¼Œç”¨æˆ·è¾“å…¥: {user_input[:50]}..." if len(user_input) > 50 else f"å¼€å§‹åˆ›å»ºæ‰§è¡Œè®¡åˆ’ï¼Œç”¨æˆ·è¾“å…¥: {user_input}")
            # è·å–å¯¹è¯æ‘˜è¦
            conversation_summary = self._summarize_conversation(user_id)
            debug(f"å¯¹è¯æ‘˜è¦: {conversation_summary}")
            # åˆ›å»ºè§„åˆ’æç¤ºè¯
            prompt = self._create_planning_prompt(user_input, conversation_summary)
            
            # LLMç”Ÿæˆè®¡åˆ’
            try:
                response = self.llm.chat(prompt)
                debug("LLMè®¡åˆ’ç”Ÿæˆå®Œæˆ")
            except ConnectionError as ce:
                error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {ce}")
                return [{"step": 1, "action": "ç›´æ¥å›ç­”", "reason": "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè¯¦ç»†è®¡åˆ’"}]
            except Exception as e:
                error(f"LLMè°ƒç”¨é”™è¯¯: {e}")
                return [{"step": 1, "action": "ç›´æ¥å›ç­”", "reason": "LLMè°ƒç”¨å¼‚å¸¸ï¼Œæ— æ³•ç”Ÿæˆè¯¦ç»†è®¡åˆ’"}]
            
            # è§£ææå–è®¡åˆ’
            plan = self._extract_plan_from_response(response)
            debug(f"æ‰§è¡Œè®¡åˆ’åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(plan)} ä¸ªæ­¥éª¤")
            return plan
        except Exception as e:
            error(f"è§„åˆ’é”™è¯¯: {e}")
            exception("æ‰§è¡Œè®¡åˆ’åˆ›å»ºå¼‚å¸¸")
            return [{"step": 1, "action": "ç›´æ¥å›ç­”", "reason": "æ— æ³•ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"}]

    # æå–æœ€ç»ˆç»“æœ
    def _parsed_repose(self,response) -> str:
        """ä»å“åº”ä¸­æå–æœ€ç»ˆå›ç­”ç»“æœï¼Œä¿ç•™</think>æ ‡è®°åçš„å†…å®¹"""
        debug(f"å¼€å§‹è§£æå“åº”å†…å®¹ï¼Œé•¿åº¦: {len(response)} å­—ç¬¦")
        try:
            # æå–</think>æ ‡ç­¾åçš„å†…å®¹
            if '</think>' in response:
                response = response.split('</think>')[-1]
            return response.strip()
        except Exception as e:
            debug(f"è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return response.strip()

    def _summarize_conversation(self,user_id: int) -> str:
        """æ€»ç»“å¯¹è¯å†å²"""
        history = db.get_chat_history(user_id,3) # è·å–æœ€è¿‘çš„3æ¡å†å²å¯¹è¯è®°å½•
        debug(f"æ€»ç»“å¯¹è¯å†å²ï¼Œæ€»è®°å½•æ•°: {len(history)}")
        if not history:
            debug("å¯¹è¯å†å²ä¸ºç©º")
            return "æš‚æ— å†å²å¯¹è¯"
        summary = "\n".join([f"[ç”¨æˆ·é—®é¢˜: {record['user_message']}; AIå›åº”: {record.get('bot_response', 'æ— ç»“æœ')}]" for record in history])
        # é™åˆ¶æ€»ç»“çš„å¯¹è¯æ•°é‡
        debug(f"å¯¹è¯å†å²æ€»ç»“å®Œæˆï¼Œæ‘˜è¦é•¿åº¦: {len(summary)} å­—ç¬¦")
        return summary
    
    # è§£æLLMè¿”å›çš„æ‰§è¡Œè®¡åˆ’åˆ—è¡¨
    def _extract_plan_from_response(self, response: str) -> List[Dict]:
        """ä»LLMå“åº”ä¸­æå–æ‰§è¡Œè®¡åˆ’"""
        # print(f"LLMåˆ¶å®šæ‰§è¡Œè®¡åˆ’è¿”å›: {response}")
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            try:
                return json.loads(response)
            except json.JSONDecodeError:
                # å°è¯•æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
        except:
            pass
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤è®¡åˆ’
        return [{"step": 1, "action": "ç›´æ¥å›ç­”", "reason": "æ— æ³•è§£æè®¡åˆ’"}]


    

    # æå–LLMè¿”å›çš„å·¥å…·ä¿¡æ¯
    def _extract_json_from_response(self, response_text: str) -> Optional[Dict]:
        """ä»å“åº”ä¸­æå–JSON"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            cleaned_text = response_text.strip()
            
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(cleaned_text)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONå¯¹è±¡
            json_match = re.search(r'```json\s*({.*?})\s*```', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            
            # å°è¯•ç›´æ¥åŒ¹é…JSONå¯¹è±¡ï¼ˆå³ä½¿æ²¡æœ‰ ```json æ ‡è®°ï¼‰
            json_match = re.search(r'(\{.*?\})', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            
            return None
    
    def _validate_parsed_result(self, result: Dict) -> bool:
        """éªŒè¯è§£æç»“æœçš„æœ‰æ•ˆæ€§ï¼Œæ ¼å¼å’Œtoolæ˜¯å¦å­˜åœ¨"""
        try:
            debug(f"å¼€å§‹éªŒè¯è§£æç»“æœï¼Œç±»å‹: {type(result).__name__}")
            if not isinstance(result, dict):
                debug("éªŒè¯å¤±è´¥: è§£æç»“æœä¸æ˜¯å­—å…¸ç±»å‹")
                return False
            
            tool_name = result.get("tool")
            parameters = result.get("parameters", {})
            
            if not tool_name:
                debug("éªŒè¯å¤±è´¥: å·¥å…·åç§°ä¸ºç©º")
                return False
                
            if tool_name not in self.tools:
                debug(f"éªŒè¯å¤±è´¥: å·¥å…· {tool_name} ä¸å­˜åœ¨")
                return False
            
            if not isinstance(parameters, dict):
                debug("éªŒè¯å¤±è´¥: å‚æ•°ä¸æ˜¯å­—å…¸ç±»å‹")
                return False
            
            # æ£€æŸ¥å¿…éœ€å‚æ•°
            tool = self.tools[tool_name]
            required_params = [p["name"] for p in tool.parameters if p["required"]]
            missing_params = [param for param in required_params if param not in parameters]
            
            if missing_params:
                debug(f"éªŒè¯å¤±è´¥: ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_params}")
                return False
            
            debug(f"éªŒè¯æˆåŠŸ: å·¥å…· {tool_name} çš„å‚æ•°æœ‰æ•ˆ")
            return True
        except Exception as e:
            debug(f"éªŒè¯å¼‚å¸¸: {e}")
            return False
    
    def execute_tool(self, tool_name: str, parameters: Dict[str, Any]) -> Any:
        """æ‰§è¡Œå·¥å…·"""
        info(f"æ‰§è¡Œå·¥å…·: {tool_name}, å‚æ•°: {parameters}")
        if tool_name not in self.tools:
            error(f"æœªçŸ¥å·¥å…·: {tool_name}")
            raise ValueError(f"æœªçŸ¥å·¥å…·: {tool_name}")
        
        try:
            tool = self.tools[tool_name]  #è·å–jsonä¸­çš„tool(ç±»Tool)
            result = tool.execute(**parameters) # parameterså‡½æ•°å‚æ•°å€¼
            info(f"å·¥å…·æ‰§è¡ŒæˆåŠŸ: {tool_name}")
            debug(f"å·¥å…·æ‰§è¡Œç»“æœ: {str(result)[:200]}..." if len(str(result)) > 200 else f"å·¥å…·æ‰§è¡Œç»“æœ: {result}")
            return result
        except Exception as e:
            error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_name}, é”™è¯¯: {str(e)}")
            exception("å·¥å…·æ‰§è¡Œå¼‚å¸¸")
            raise
    
    def process_query(self, user_id :int, user_input: str, model_name: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨Reactæ¨¡å¼ï¼šæ€è€ƒã€è¡ŒåŠ¨ã€è§‚å¯Ÿã€å“åº”"""
        info(f"å¼€å§‹å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_input[:50]}..." if len(user_input) > 50 else f"å¼€å§‹å¤„ç†ç”¨æˆ·æŸ¥è¯¢: {user_input}")
        # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ‰§è¡Œè®¡åˆ’
        plan = self.create_plan(user_input,user_id)
        
        # è®°å½•æ‰§è¡Œè®¡åˆ’
        execution_summary = f"æ‰§è¡Œè®¡åˆ’: {json.dumps(plan, ensure_ascii=False)}"
        debug(execution_summary)
        
        final_response = ""
        tool_results = []  # å­˜å‚¨æ‰€æœ‰å·¥å…·æ‰§è¡Œç»“æœ
        previous_step_result=""   #è®°å½•æ¯ä¸ªé—®é¢˜çš„æ‰§è¡Œè®¡åˆ’ä¸Šä¸€æ­¥éª¤ç»“æœï¼Œå®ç°ä¸€ä¸ªé—®é¢˜é‡Œé¢ï¼Œå½“å‰æ­¥éª¤å®ç°æœ‰æ—¶éœ€è¦ä¾èµ–ä¸Šä¸€ä¸ªæ­¥éª¤ç»“æœ
        # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œè®¡åˆ’ä¸­çš„æ¯ä¸ªæ­¥éª¤
        for step in plan:
            step_number = step.get("step", 1)
            action = step.get("action", "ç›´æ¥å›ç­”")
            reason = step.get("reason", "")
 
            # æ ¹æ®åŠ¨ä½œç±»å‹æ‰§è¡Œä¸åŒæ“ä½œ
            if action == "ä½¿ç”¨å·¥å…·":
                # è§£æç”¨æˆ·è¾“å…¥ä»¥è·å–å·¥å…·ä¿¡æ¯
                # å¯¹äºå¤šæ­¥éª¤è®¡åˆ’ï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®å½“å‰æ­¥éª¤çš„reasonæ¥ç¡®å®šè¦ä½¿ç”¨çš„å·¥å…·
                if not previous_step_result:
                    step_specific_input = f"{user_input} (æ ¹æ®è®¡åˆ’å¼€å§‹æ‰§è¡Œç¬¬{step_number}æ­¥ï¼š{reason})"
                else :
                    step_specific_input = f"{user_input} (ç¬¬{step_number-1}æ­¥æ‰§è¡Œç»“æœï¼š{previous_step_result}ï¼›æ ¹æ®è®¡åˆ’å¼€å§‹æ‰§è¡Œç¬¬{step_number}æ­¥ï¼š{reason})"
                # æ ¹æ®æ‰§è¡Œè®¡åˆ’æ­¥éª¤ï¼Œä½¿ç”¨LLMå»ç”Ÿæˆå¯¹åº”çš„å·¥å…·å’Œå‚æ•°ä¿¡æ¯
                parsed = self.parse_user_input(step_specific_input, user_id)
                tool_name = parsed.get("tool")
                parameters = parsed.get("parameters", {})
                reasoning = parsed.get("reasoning", "")
                confidence = parsed.get("confidence", 0)
                
                # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä»è®¡åˆ’çš„reasonä¸­æå–å·¥å…·å
                if not tool_name and "tool_name" in step:
                    tool_name = step["tool_name"]
                debug(f"è°ƒç”¨çš„å·¥å…·ï¼š{tool_name}, å·¥å…·ç½®ä¿¡åº¦ï¼š{confidence}")
                # è·å–å·¥å…·ä¿¡æ¯ä»¥è·å–tool_id
                tool_info = db.get_function_tool_name(tool_name)
                tool_id = tool_info['tool_id'] if tool_info else None
                if tool_id and confidence >= 0.3:
                    try:
                        # æ ¹æ®æ‰§è¡Œè®¡åˆ’ä¸­çš„å·¥å…·å’Œå‚æ•°ï¼Œæ‰§è¡Œå·¥å…·
                        execution_start_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") # è®°å½•å¼€å§‹æ—¶é—´ï¼ˆå¹´æœˆæ—¥æ—¶åˆ†ç§’æ ¼å¼ï¼‰
                        result = self.execute_tool(tool_name, parameters)
                        execution_end_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") # è®°å½•ç»“æŸæ—¶é—´
                        previous_step_result=result  #ä¿å­˜å½“å‰ç»“æœ
                        
                        # è®°å½•å·¥å…·æ‰§è¡Œä¿¡æ¯
                        execution_params_str = json.dumps(parameters, ensure_ascii=False)
                        execution_result_str = json.dumps(result, ensure_ascii=False) if not isinstance(result, str) else result
                        execution_steps = json.dumps({
                            'step': step_number,
                            'reasoning': reasoning,
                            'confidence': confidence
                        }, ensure_ascii=False)
                        # è®°å½•å·¥å…·æ‰§è¡Œä¿¡æ¯
                        db.add_tool_execution(
                            user_id=user_id,
                            tool_id=tool_id,
                            tool_name=tool_name,
                            question=user_input,
                            execution_steps=execution_steps,
                            execution_params=execution_params_str,
                            execution_result=execution_result_str,
                            execution_status="success",
                            start_time=execution_start_time,
                            end_time=execution_end_time
                        )
                        
                        # æ ¼å¼åŒ–å­˜å‚¨å·¥å…·æ‰§è¡Œç»“æœ
                        tool_response = self._format_response(tool_name, parameters, result, reasoning, confidence)
                        tool_results.append(tool_response)
                        
                    except Exception as e:
                        error_msg = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
                        tool_results.append(error_msg)
                        error(f"è°ƒç”¨å·¥å…·æ‰§è¡Œé”™è¯¯: {error_msg}")
                        exception("å·¥å…·è°ƒç”¨å¼‚å¸¸") 
                else:
                    # å¦‚æœæ²¡æœ‰åˆé€‚çš„å·¥å…·ï¼Œç”Ÿæˆç›´æ¥å›ç­”
                    debug(f"æ²¡æœ‰åˆé€‚çš„å·¥å…·æˆ–æ•°æ®åº“ä¸­æ— æ­¤å·¥å…·ä¿¡æ¯{tool_name}ï¼Œç”Ÿæˆç›´æ¥å›ç­”")
                    fallback_answer = self._generate_direct_answer(step_specific_input,user_id)
                    tool_results.append(fallback_answer)
                    debug(f"ç›´æ¥å›ç­”ç”Ÿæˆå®Œæˆ")
            
            elif action == "ç›´æ¥å›ç­”":
                # å¯¹äºç›´æ¥å›ç­”ï¼Œä½¿ç”¨æ‰€æœ‰å·¥å…·æ‰§è¡Œç»“æœä½œä¸ºä¸Šä¸‹æ–‡
                try:
                    # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“å›ç­”,è¿™é‡Œä¸éœ€è¦æ·»åŠ å†å²å¯¹è¯ï¼Œå› ä¸ºç›´æ¥å›ç­”æ˜¯åŸºäºå½“å‰é—®é¢˜çš„å·¥å…·æ‰§è¡Œç»“æœï¼Œè€Œä¸æ˜¯åŸºäºä¹‹å‰çš„å¯¹è¯
                    if tool_results:
                    # æ„å»ºåŒ…å«æ‰€æœ‰å·¥å…·ç»“æœçš„æç¤ºè¯æ–‡æœ¬å­—ç¬¦ä¸²
                        context = "\n\n".join(tool_results)
                        debug(f"å·¥å…·è¿”å›çš„ç»“æœï¼š\n{context}")
                        direct_answer_prompt = f"""åŸºäºä»¥ä¸‹å·¥å…·æ‰§è¡Œç»“æœï¼Œæ€»ç»“å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
                                                ç”¨æˆ·é—®é¢˜: {user_input}

                                                å·¥å…·æ‰§è¡Œç»“æœ:
                                                {context}

                                                è¯·æä¾›ä¸€ä¸ªç®€æ´ã€å‹å¥½çš„æ€»ç»“å›ç­”ã€‚"""
                        response = self.llm.chat(direct_answer_prompt)
                        final_response = response.strip()
                        debug("æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœæ€»ç»“å›ç­”ç”ŸæˆæˆåŠŸ")
                    else:
                        final_response = self._generate_follow_up_question(user_input)
                        debug("æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œç›´æ¥æ€»ç»“å›ç­”ç”ŸæˆæˆåŠŸ")

                except Exception as e:
                    error(f"ç”Ÿæˆæ€»ç»“å›ç­”å¤±è´¥: {str(e)}")
                    # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å·¥å…·ç»“æœçš„ç®€å•æ‹¼æ¥
                    result_lines = []
                    for r in tool_results:
                        if "**ç»“æœ**: " in r:
                            result_part = r.split("**ç»“æœ**: ")[-1]
                            first_line = result_part.split("\n")[0]
                            result_lines.append(f"- {first_line}")
                    final_response = "æ ¹æ®å·¥å…·å¤„ç†ç»“æœï¼š\n" + "\n".join(result_lines)

                break  # ç›´æ¥å›ç­”æ­¥éª¤æ˜¯æœ€åä¸€æ­¥ï¼Œæ‰§è¡Œå®Œåå¯ä»¥è·³å‡ºå¾ªç¯
            
            elif action == "è¿½é—®ç”¨æˆ·":
                # ç”Ÿæˆè¿½é—®
                final_response = self._generate_follow_up_question(user_input)
                # print(final_response)
                break  # è¿½é—®åéœ€è¦ç”¨æˆ·è¾“å…¥ï¼Œè·³å‡ºå¾ªç¯
            
            else:
                # æœªçŸ¥åŠ¨ä½œç±»å‹ï¼Œé»˜è®¤ç›´æ¥å›ç­”
                final_response = self._generate_direct_answer(user_input, user_id)
                # print(final_response)
                break
        
        # self.update_memory(user_input, final_response)
        
        # å…ˆè¾“å‡ºå½“å‰è®¡åˆ’ï¼Œå†è¾“å‡ºå›ç­”
        plan_text = "\n**ğŸ“‹å½“å‰æ‰§è¡Œè®¡åˆ’**:\n"
        if plan:
            for i, step in enumerate(plan, 1):
                action = step.get("action", "æœªçŸ¥åŠ¨ä½œ")
                reason = step.get("reason", "")
                plan_text += f"æ­¥éª¤{i}ï¼š{action}"
                if reason:
                    plan_text += f" - {reason}"
                plan_text += "\n"
        else:
            plan_text += "æš‚æ— æ‰§è¡Œè®¡åˆ’\n"
        # å­˜å‚¨å¯¹è¯è®°å½•åˆ°æ•°æ®åº“
        debug("å­˜å‚¨Agentè®°å¿†")
        db.add_chat_record(
            user_message=user_input,
            plan=plan_text,
            bot_response=self._parsed_repose(final_response),
            user_id=user_id,
            model_name=model_name
        )

        info("ç”¨æˆ·æŸ¥è¯¢å¤„ç†å®Œæˆ")
        return plan_text ,final_response
    
    def _generate_direct_answer(self, user_input: str, user_id: int) -> str:
        """ç›´æ¥ç”Ÿæˆå›ç­”ï¼Œä¸ä½¿ç”¨å·¥å…·"""
        try:
            # æ„å»ºç›´æ¥å›ç­”çš„æç¤ºè¯
            prompt = f"""
            è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸éœ€è¦è°ƒç”¨å·¥å…·ï¼š
            ç”¨æˆ·é—®é¢˜ï¼š{user_input}
            
            å†å²å¯¹è¯ï¼š
            {self._summarize_conversation(user_id)}
            
            è¯·æä¾›ä¸€ä¸ªè‡ªç„¶ã€å‹å¥½çš„å›ç­”ã€‚
            """
            
            try:
                response = self.llm.chat(prompt)
                return response.strip()
            except ConnectionError:
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•è¿æ¥åˆ°è¯­è¨€æ¨¡å‹æœåŠ¡ã€‚è¯·ç¨åå†è¯•ã€‚"
            except Exception as e:
                return f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"
        except Exception as e:
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"
    
    def _generate_follow_up_question(self, user_input: str) -> str:
        """ç”Ÿæˆè¿½é—®ç”¨æˆ·çš„é—®é¢˜"""
        try:
            # æ„å»ºè¿½é—®æç¤ºè¯
            prompt = f"""
            ç”¨æˆ·çš„é—®é¢˜ç¼ºå°‘ä¸€äº›å¿…è¦ä¿¡æ¯ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªå‹å¥½çš„è¿½é—®ï¼š
            ç”¨æˆ·é—®é¢˜ï¼š{user_input}
            
            è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´ã€æ˜ç¡®çš„è¿½é—®ï¼Œå¸®åŠ©è·å–æ›´å¤šä¿¡æ¯ä»¥ä¾¿æ›´å¥½åœ°å›ç­”é—®é¢˜ã€‚
            """
            
            try:
                response = self.llm.chat(prompt)
                return response.strip()
            except ConnectionError:
                return "ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œæˆ‘éœ€è¦ä¸€äº›é¢å¤–ä¿¡æ¯ã€‚æ‚¨èƒ½æä¾›æ›´å¤šç»†èŠ‚å—ï¼Ÿ"
            except Exception as e:
                return "ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œæˆ‘éœ€è¦ä¸€äº›é¢å¤–ä¿¡æ¯ã€‚æ‚¨èƒ½æä¾›æ›´å¤šç»†èŠ‚å—ï¼Ÿ"
        except Exception as e:
            return "ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œæˆ‘éœ€è¦ä¸€äº›é¢å¤–ä¿¡æ¯ã€‚æ‚¨èƒ½æä¾›æ›´å¤šç»†èŠ‚å—ï¼Ÿ"
    
    def _format_response(self, tool_name: str, parameters: Dict, result: Any, 
                        reasoning: str, confidence: float) -> str:
        """æ ¼å¼åŒ–å“åº”"""
        tool = self.tools[tool_name]
        
        response = f"\n**ğŸ”§å·¥å…·æ‰§è¡Œç»“æœå¦‚ä¸‹**: \n"
        response = f"**å·¥å…·å**: {tool.name}\n"
        response += f"**åŠŸèƒ½æè¿°**: {tool.description}\n"
        response += f"**å‚æ•°**: {parameters}\n"
        response += f"**ç»“æœ**: {result}\n"
        
        if reasoning:
            response += f"**æ¨ç†è¿‡ç¨‹**: {reasoning}\n"
        response += f"**ç½®ä¿¡åº¦**: {confidence:.2f}"
        
        return response
    
    
    def get_execution_history(self,user_id: int ,limit: int = 5) -> list:
        """è·å–å·¥å…·æ‰§è¡Œå†å²ï¼ˆè¿”å›åˆ—è¡¨æ ¼å¼ï¼‰"""
        tool_history = db.get_user_tool_executions(user_id=user_id, limit=limit)
        if not tool_history:
            return []
        
        # è¿”å›åˆ—è¡¨æ ¼å¼ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯åŒ…å«æ‰§è¡Œå†å²è¯¦æƒ…çš„å­—å…¸
        result_list = []
        for i, record in enumerate(tool_history, 1):
            # é™åˆ¶ç»“æœæ˜¾ç¤ºé•¿åº¦
            execution_result = str(record['execution_result'])
            truncated_result = execution_result[:100] + ('...' if len(execution_result) > 100 else '')
            result_list.append({
                'index': i,
                'question': record['question'],
                'tool_name': record['tool_name'],
                'params': record['execution_params'],
                'start_time': record['start_time'],
                'end_time': record['end_time'],
                'result': truncated_result
            })
        
        return result_list
    
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        debug(f"è·å–å½“å‰æ—¶é—´: {current_time}")
        return current_time
    


